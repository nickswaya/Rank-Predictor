{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
   }
  },
  "interpreter": {
   "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from random import randrange, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from helper import *\n",
    "import math\n",
    "import logging\n",
    "from retrying import retry\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from itertools import islice\n",
    "from sklearn.ensemble import (GradientBoostingRegressor, GradientBoostingClassifier, AdaBoostClassifier,RandomForestClassifier)\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pylab import rcParams\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('ggplot')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d['list'][0].keys()\n",
    "replay_ids = []\n",
    "for i in range(200):\n",
    "    replay_ids.append(d['list'][i]['id'])\n",
    "replay_ids[0:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def remove_extra_element(row):\n",
    "    if 'goals_against_while_last_defender' in row:\n",
    "        del row['goals_against_while_last_defender']\n",
    "    return row\n",
    "\n",
    "\n",
    "def create_frame_from_json(json_stats, rank_target):\n",
    "    df = pd.DataFrame.from_dict(json_stats)\n",
    "\n",
    "    df['core'] = df.stats.apply(lambda x:x['core'])\n",
    "    df['boost'] = df.stats.apply(lambda x:x['boost'])\n",
    "    df['movement'] = df.stats.apply(lambda x:x['movement'])\n",
    "    df['positioning'] = df.stats.apply(lambda x:x['positioning'])\n",
    "    df['demo'] = df.stats.apply(lambda x:x['demo'])\n",
    "    \n",
    "\n",
    "    rank_keys = list(df.iloc[0]['rank'].keys())\n",
    "    camera_keys = list(df.iloc[0]['camera'].keys())\n",
    "    core_stats_keys = list(df.iloc[0]['stats']['core'].keys())\n",
    "    boost_keys = list(df.iloc[0]['stats']['boost'].keys())\n",
    "    movement_keys = list(df.iloc[0]['stats']['movement'].keys())\n",
    "    positioning_keys = ['avg_distance_to_ball', 'avg_distance_to_ball_possession',\n",
    "        'avg_distance_to_ball_no_possession', 'avg_distance_to_mates',\n",
    "        'time_defensive_third', 'time_neutral_third', 'time_offensive_third',\n",
    "        'time_defensive_half', 'time_offensive_half', 'time_behind_ball',\n",
    "        'time_infront_ball', 'time_most_back', 'time_most_forward',\n",
    "        'time_closest_to_ball', 'time_farthest_from_ball',\n",
    "        'percent_defensive_third', 'percent_offensive_third',\n",
    "        'percent_neutral_third', 'percent_defensive_half',\n",
    "        'percent_offensive_half', 'percent_behind_ball', 'percent_infront_ball',\n",
    "        'percent_most_back', 'percent_most_forward', 'percent_closest_to_ball',\n",
    "        'percent_farthest_from_ball']\n",
    "    demo_keys = list(df.iloc[0]['stats']['demo'].keys())\n",
    "\n",
    "    df[rank_keys] = pd.json_normalize(df['rank'])\n",
    "    df[camera_keys] = pd.json_normalize(df['camera'])\n",
    "    df[core_stats_keys] = pd.json_normalize(df['core'])\n",
    "    df[boost_keys] = pd.json_normalize(df['boost'])\n",
    "    df[movement_keys] = pd.json_normalize(df['movement'])\n",
    "    df[demo_keys] = pd.json_normalize(df['demo'])\n",
    "\n",
    "    df['positioning'] = df.stats.apply(lambda x: remove_extra_element(x['positioning']))\n",
    "    df[positioning_keys] = pd.json_normalize(df['positioning'])\n",
    "    if rank_target == 'tier_div':\n",
    "        df['rank_target'] = df['tier'] * 4 + df['division']\n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df\n",
    "    if rank_target == 'tier':\n",
    "        df['rank_target'] = df['id'] \n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_all_ids():\n",
    "    season_lst = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','f1', 'f2', 'f3', 'f4']\n",
    "    replay_ids = []\n",
    "    for i in range(len(season_lst)):\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?player-name=LebaneseNinja&player-id=steam:76561198068157523&count=200&playlist=ranked-standard&season={season_lst[i]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        replay_ids.append(rank_ids)\n",
    "    return replay_ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stats_from_replays(replay_ids):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "\n",
    "    orange_ranks = []\n",
    "    orange_stats = []\n",
    "    blue_ranks = []\n",
    "    blue_stats = []\n",
    "    pull_num = 0\n",
    "    for replay_id in replay_ids:\n",
    "        replay_stats = requests.get(f'https://ballchasing.com/api/replays/{replay_id}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        test_stats = replay_stats.json()\n",
    "        try:\n",
    "            ranks = [test_stats['orange']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            orange_ranks.append(ranks)\n",
    "            stats = [test_stats['orange']['players'][player] for player in range(3)]\n",
    "            orange_stats.append(stats[0])\n",
    "            orange_stats.append(stats[1])\n",
    "            orange_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ranks = [test_stats['blue']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            blue_ranks.append(ranks)\n",
    "            stats = [test_stats['blue']['players'][player] for player in range(3)]\n",
    "            blue_stats.append(stats[0])\n",
    "            blue_stats.append(stats[1])\n",
    "            blue_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        pull_num += 1\n",
    "        logger.info(f'stats extracted for pull num {pull_num}')\n",
    "        \n",
    "    return blue_stats, orange_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def combine_clean_dfs(blue_df, orange_df, car_dummies):\n",
    "    combined_dfs = blue_df.append(orange_df)\n",
    "    combined_dfs['mvp'] = combined_dfs.mvp.apply(lambda x: 1 if x==True else 0)\n",
    "\n",
    "    if car_dummies == False:\n",
    "        combined_dfs = combined_dfs.drop('car_name', axis=1)\n",
    "        return combined_dfs\n",
    "    if car_dummies == True:\n",
    "        dummies = pd.get_dummies(combined_dfs.car_name, drop_first=True)\n",
    "        combined_concat_w_dummies = pd.concat([combined_dfs, dummies], axis=1)\n",
    "        combined_concat_w_dummies = combined_concat_w_dummies.drop('car_name', axis=1)\n",
    "        return combined_concat_w_dummies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_random_ids():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "    logger.info('starting pull')\n",
    "    minmax_rank_lst = [['bronze-1', 'bronze-3'], ['silver-1', 'silver-3'], ['gold-1', 'gold-3'], ['platinum-1', 'platinum-3'], ['diamond-1', 'diamond-3'], ['champion-1', 'champion-3'], ['champion-3', 'grand-champion']]\n",
    "    replay_ids = []\n",
    "    ids_pulled = []\n",
    "    for i in range(len(minmax_rank_lst)):\n",
    "        logger.info(f'pulling min_rank={minmax_rank_lst[i][0]}, max_rank = {minmax_rank_lst[i][1]}')\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard&min-rank={minmax_rank_lst[i][0]}&max-rank={minmax_rank_lst[i][1]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        count = d['count']\n",
    "        logger.info(f'count = {count}')\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "        if i == 6 or i == 5:\n",
    "            logger.info('i == 5 or 6, moving on')\n",
    "            replay_ids.append(rank_ids)\n",
    "            continue \n",
    "\n",
    "        logger.info('starting second pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "\n",
    "        logger.info('starting third pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        logger.info('rank pull complete.. appending results and moving to next rank') \n",
    "        replay_ids.append(rank_ids)\n",
    "\n",
    "    flat_list = [item for sublist in replay_ids for item in sublist]\n",
    "    return flat_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('full_nodummies.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "y = df.pop('rank_target')\n",
    "X = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "kf = KFold(10)\n",
    "rf_pipe = Pipeline([('classifier', GradientBoostingRegressor())])\n",
    "rf_grid_params = {'classifier__max_features': ['sqrt', 'log2'], 'classifier__n_estimators': [900, 1000, 1100]}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'neg_mean_absolute_error')\n",
    "rf_grid.fit(X_train, y_train) \n",
    "print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))\n",
    "\n",
    "'''\n",
    "best estimator : [('classifier',\n",
    "                 GradientBoostingRegressor(max_features='sqrt',\n",
    "                                           n_estimators=900))])\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "axs = axs.flatten()\n",
    "axs[0].hist(y_train)\n",
    "axs[0].set_title('y_train rank distribution')\n",
    "axs[0].set_ylabel('count')\n",
    "axs[0].set_xlabel('rank target')\n",
    "axs[1].hist(y_test)\n",
    "axs[1].set_title('y_test rank distribution')\n",
    "axs[1].set_ylabel('count')\n",
    "axs[1].set_xlabel('rank target');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "keras = tf.keras\n",
    "\n",
    "NN_model = keras.models.Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(keras.layers.Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(45, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split = 0.2)\n",
    "'''\n",
    "224/224 [==============================] - 0s 831us/step - loss: 7.2956 - mean_absolute_error: 7.2956 - val_loss: 7.2235 - val_mean_absolute_error: 7.2235\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_all():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "    logger.info('starting pull')\n",
    "    minmax_rank_lst = [['champion-1', 'champion-3'], ['champion-3', 'grand-champion']]\n",
    "    replay_ids = []\n",
    "    ids_pulled = []\n",
    "    for i in range(len(minmax_rank_lst)):\n",
    "        logger.info(f'pulling min_rank={minmax_rank_lst[i][0]}, max_rank = {minmax_rank_lst[i][1]}')\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard&min-rank={minmax_rank_lst[i][0]}&max-rank={minmax_rank_lst[i][1]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        count = d['count']\n",
    "        next_link = d['next']\n",
    "        logger.info(f'count = {count}')\n",
    "        for pull in range(math.floor(count/200)-2):\n",
    "            logger.info(f'starting pull number {pull+1}')\n",
    "            r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "            d = r.json()\n",
    "            try:\n",
    "                for i in range(len(d['list'])):\n",
    "                    rank_ids.append(d['list'][i]['id'])\n",
    "            except:\n",
    "                pass\n",
    "            next_link = d['next']\n",
    "        logger.info('rank pull complete.. appending results, saving series and moving to next rank') \n",
    "        replay_ids.append(rank_ids)\n",
    "        match_ids_tosave = pd.Series(replay_ids)\n",
    "        match_ids_tosave.to_csv('test_pull_all_ids.csv')\n",
    "    flat_list = [item for sublist in replay_ids for item in sublist]\n",
    "    return flat_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "up_to_d1 = pd.read_csv('up_to_diamond1.csv')\n",
    "d1uptochamp = pd.read_csv('diamond1_uptochamp1.csv')\n",
    "champtogc = pd.read_csv('champ_to_gc.csv')\n",
    "\n",
    "\n",
    "d1uptochampa = d1uptochamp.iloc[0]['0']\n",
    "da = d1uptochampa.split(',')\n",
    "da = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in da]\n",
    "\n",
    "\n",
    "champtogca = champtogc.iloc[0]['0']\n",
    "gca = champtogca.split(',')\n",
    "gca = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in gca]\n",
    "\n",
    "champtogcb = champtogc.iloc[1]['0']\n",
    "gcb = champtogcb.split(',')\n",
    "gcb = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in gcb]\n",
    "\n",
    "\n",
    "up_to_d1_a = up_to_d1.iloc[0]['0']\n",
    "a = up_to_d1_a.split(',')\n",
    "a = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in a]\n",
    "\n",
    "up_to_d1_b = up_to_d1.iloc[1]['0']\n",
    "b = up_to_d1_b.split(',')\n",
    "b = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in b]\n",
    "\n",
    "up_to_d1_c = up_to_d1.iloc[2]['0']\n",
    "c = up_to_d1_c.split(',')\n",
    "c = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in c]\n",
    "\n",
    "up_to_d1_d = up_to_d1.iloc[3]['0']\n",
    "d = up_to_d1_d.split(',')\n",
    "d = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in d]\n",
    "\n",
    "res = []\n",
    "res.append(a)\n",
    "res.append(b)\n",
    "res.append(c)\n",
    "res.append(d)\n",
    "res.append(da)\n",
    "res.append(gca)\n",
    "res.append(gcb)\n",
    "\n",
    "flat_list = [item for sublist in res for item in sublist]\n",
    "res1 = []\n",
    "for i in flat_list:\n",
    "    if i not in res1:\n",
    "        res1.append(i)\n",
    "res1 = [i.replace(' ', '') for i in res1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# '27,095'\n",
    "# blue_stats, orange_stats = get_stats_from_replays(res1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# blue_df = create_frame_from_json(blue_stats, 'tier_div')\n",
    "# orange_df = create_frame_from_json(orange_stats, 'tier_div')\n",
    "# full_df = combine_clean_dfs(blue_df, orange_df, car_dummies=False)\n",
    "# full_df = full_df.dropna()\n",
    "# full_df.to_csv('final_full_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "\n",
    "train, holdout = train_test_split(X, y)\n",
    "holdout_y = holdout.pop('rank_target')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "\n",
    "keras = tf.keras\n",
    "\n",
    "NN_model = keras.models.Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(keras.layers.Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(45, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split = 0.2)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_train = np.mean(y_train)\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))\n",
    "\n",
    "'''\n",
    "Baseline MAE is 7.85\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "params['eval_metric'] = \"mae\"\n",
    "num_boost_round = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# kf = KFold(10)\n",
    "# rf_pipe = Pipeline([('classifier', GradientBoostingRegressor())])\n",
    "# rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'neg_mean_absolute_error')\n",
    "# rf_grid.fit(X_train, y_train) \n",
    "# print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cv_results['test-mae-mean'].min()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(2,4)\n",
    "    for min_child_weight in range(2,4)\n",
    "]\n",
    "params['gpu_id'] = 0\n",
    "params['tree_method'] = 'gpu_hist'\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))    \n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )  \n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params['max_depth'] = 2\n",
    "params['min_child_weight'] = 3\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "        print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params['subsample'] = 1.\n",
    "params['colsample_bytree'] = .8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%time\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005, .001, .0005]:\n",
    "    print(\"CV with eta={}\".format(eta))    # We update our parameters\n",
    "    params['eta'] = eta    # Run and time CV\n",
    "    %time cv_results = xgb.cv(params,dtrain,num_boost_round=num_boost_round,seed=42,nfold=5,metrics=['mae'],early_stopping_rounds=10)    \n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, MAE: {}\".format(best_params, min_mae))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params['eta'] = .2\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "'''\n",
    "[966]\tTest-mae:5.04715\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_boost_round = model.best_iteration + 1\n",
    "best_model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")]\n",
    ")\n",
    "'''\n",
    "[957]\tTest-mae:5.04667\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_absolute_error(best_model.predict(dtest), y_test)\n",
    "best_model.save_model(\"tuned_XGBoost.model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "loaded_model = xgb.Booster()\n",
    "loaded_model.load_model(\"tuned_XGBoost.model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# full_df = pd.read_csv('final_full_data.csv')\n",
    "# full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "# full_df = full_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# train, holdout = train_test_split(full_df, test_size=0.2)\n",
    "\n",
    "# label = np.array(train.pop('rank_target'))\n",
    "# X = np.array(train)\n",
    "# dtrain = xgb.DMatrix(X, label=label)\n",
    "\n",
    "# holdout_label = np.array(holdout.pop('rank_target'))\n",
    "# holdout_X = np.array(holdout)\n",
    "# holdout_dtest = xgb.DMatrix(holdout_X, label=holdout_label)\n",
    "\n",
    "\n",
    "# param = {'eval_metric': 'mae'}\n",
    "# param['nthread'] = 6\n",
    "# evallist = [(dtrain, 'train')]\n",
    "\n",
    "# bst = xgb.train(param, dtrain, 20,  evallist)\n",
    "# ypred = bst.predict(holdout_dtest)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# full_df = pd.read_csv('final_full_data.csv')\n",
    "# full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# y = full_df.pop('rank_target')\n",
    "# X = full_df\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# kf = KFold(10)\n",
    "# params = {'classifier__objective': ['reg:squarederror'], 'classifier__max_depth': np.linspace(2, 12, 6).astype(int), 'classifier__n_estimators': np.linspace(30,600,7).astype(int), 'classifier__n_jobs': [6], }\n",
    "# rf_pipe = Pipeline([('classifier', xgb.XGBRegressor())])\n",
    "# rf_grid = GridSearchCV(rf_pipe, param_grid = params, cv=kf)\n",
    "# rf_grid.fit(X_train, y_train) \n",
    "# print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rf_pipe = Pipeline([('classifier', xgb.XGBRegressor())])\n",
    "# params = {'classifier__objective': 'reg:squarederror', 'eval_metric': 'mae', 'classifier__max_depth': np.linspace(2, 12, 6), 'classifier__n_estimators': np.linspace(30,600,7), 'classifier__n_jobs': 6, }\n",
    "# rf_pipe.get_params().keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "def get_stats_from_replays_combined(replay_ids):\n",
    "    orange_stats = []\n",
    "    blue_stats = []\n",
    "    for replay_id in replay_ids:\n",
    "        replay_stats = requests.get(f'https://ballchasing.com/api/replays/{replay_id}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        test_stats = replay_stats.json()\n",
    "        try:\n",
    "            stats = [test_stats['orange']['players'][player] for player in range(3)]\n",
    "            orange_stats.append(stats[0])\n",
    "            orange_stats.append(stats[1])\n",
    "            orange_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            stats = [test_stats['blue']['players'][player] for player in range(3)]\n",
    "            blue_stats.append(stats[0])\n",
    "            blue_stats.append(stats[1])\n",
    "            blue_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "    stats = blue_stats + orange_stats\n",
    "    return stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "rank_dict = {0 :'unranked', 1: 'bronze-1', 2:'bronze-2', 3: 'bronze-3', 4: 'silver-1', 5:'silver-2',  6:'silver-3', 7:\n",
    "'gold-1', 8:'gold-2', 9:'gold-3', 10:'plat-1', 11:'plat-2', 12:'plat-3', 13:'diamond-1', 14:'diamond-2', 15:'diamond-3', 16: 'champ-1', 17:'champ-2', 18:'champ-3', 19:'grand-champ'}\n",
    "div_dict = {0.0:'division-1', 0.25:'division-2', 0.5:'division-3', 0.75:'division-4'}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "chris_id = ['212973f1-71f0-4949-8406-30e38c5811e4']\n",
    "chris_stats = get_stats_from_replays_combined(chris_id)\n",
    "chris_df, names = create_frame_from_jsonv2(chris_stats)\n",
    "chris_df = chris_df[loaded_model.feature_names]\n",
    "chris_inp = xgb.DMatrix(chris_df)\n",
    "preds = loaded_model.predict(chris_inp)\n",
    "preds_round = [round((math.floor(i))/4) for i in preds]\n",
    "div_remainder = [math.floor(i)/4 for i in preds]\n",
    "div_round = [i%1 for i in div_remainder]\n",
    "# for i in range(len(preds)):\n",
    "#     print(f'Predicted rank for {names.iloc[i]} is {rank_dict[preds_round[i]], div_dict[div_round[i]]}')\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     mvp  steering_sensitivity  fov  height  pitch  distance  stiffness  \\\n",
       "0  False                  1.45  110     110     -4       270       0.45   \n",
       "1  False                  1.30  110     110     -3       270       0.40   \n",
       "2  False                  1.37  110     110     -4       280       0.45   \n",
       "3   True                  1.30  110      90     -5       270       0.50   \n",
       "4  False                  1.05  110     100     -5       250       0.75   \n",
       "5  False                  1.00  110     110     -5       280       0.35   \n",
       "\n",
       "   swivel_speed  transition_speed  shots  ...  percent_offensive_third  \\\n",
       "0           7.0               1.4      2  ...                13.957043   \n",
       "1           4.7               1.2      2  ...                15.576112   \n",
       "2           4.7               1.2      1  ...                13.343792   \n",
       "3           6.0               1.0      2  ...                26.953548   \n",
       "4           3.9               1.3      2  ...                16.746920   \n",
       "5           2.0               1.2      3  ...                16.090190   \n",
       "\n",
       "   percent_neutral_third  percent_defensive_half  percent_offensive_half  \\\n",
       "0              35.077630               73.428260               26.571740   \n",
       "1              25.835512               71.590590               28.409412   \n",
       "2              35.035000               74.809930               25.190073   \n",
       "3              27.834307               59.529460               40.470543   \n",
       "4              37.435730               63.826660               36.173336   \n",
       "5              35.037178               65.989174               34.010830   \n",
       "\n",
       "   percent_behind_ball  percent_infront_ball  percent_most_back  \\\n",
       "0            71.710710             28.289288          28.211672   \n",
       "1            63.884980             36.115020          44.005020   \n",
       "2            60.211590             39.788406          28.860714   \n",
       "3            75.384056             24.615942          27.605902   \n",
       "4            81.396390             18.603607          33.057850   \n",
       "5            76.243580             23.756414          37.038640   \n",
       "\n",
       "   percent_most_forward  percent_closest_to_ball  percent_farthest_from_ball  \n",
       "0             36.865562                41.192505                   30.721302  \n",
       "1             33.490547                33.317467                   40.716540  \n",
       "2             26.783783                22.543377                   29.639566  \n",
       "3             38.423260                36.216520                   28.687640  \n",
       "4             29.942450                34.096320                   31.240532  \n",
       "5             29.120335                27.000130                   39.115574  \n",
       "\n",
       "[6 rows x 91 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mvp</th>\n",
       "      <th>steering_sensitivity</th>\n",
       "      <th>fov</th>\n",
       "      <th>height</th>\n",
       "      <th>pitch</th>\n",
       "      <th>distance</th>\n",
       "      <th>stiffness</th>\n",
       "      <th>swivel_speed</th>\n",
       "      <th>transition_speed</th>\n",
       "      <th>shots</th>\n",
       "      <th>...</th>\n",
       "      <th>percent_offensive_third</th>\n",
       "      <th>percent_neutral_third</th>\n",
       "      <th>percent_defensive_half</th>\n",
       "      <th>percent_offensive_half</th>\n",
       "      <th>percent_behind_ball</th>\n",
       "      <th>percent_infront_ball</th>\n",
       "      <th>percent_most_back</th>\n",
       "      <th>percent_most_forward</th>\n",
       "      <th>percent_closest_to_ball</th>\n",
       "      <th>percent_farthest_from_ball</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1.45</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>-4</td>\n",
       "      <td>270</td>\n",
       "      <td>0.45</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>13.957043</td>\n",
       "      <td>35.077630</td>\n",
       "      <td>73.428260</td>\n",
       "      <td>26.571740</td>\n",
       "      <td>71.710710</td>\n",
       "      <td>28.289288</td>\n",
       "      <td>28.211672</td>\n",
       "      <td>36.865562</td>\n",
       "      <td>41.192505</td>\n",
       "      <td>30.721302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.30</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>-3</td>\n",
       "      <td>270</td>\n",
       "      <td>0.40</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>15.576112</td>\n",
       "      <td>25.835512</td>\n",
       "      <td>71.590590</td>\n",
       "      <td>28.409412</td>\n",
       "      <td>63.884980</td>\n",
       "      <td>36.115020</td>\n",
       "      <td>44.005020</td>\n",
       "      <td>33.490547</td>\n",
       "      <td>33.317467</td>\n",
       "      <td>40.716540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>1.37</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>-4</td>\n",
       "      <td>280</td>\n",
       "      <td>0.45</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.343792</td>\n",
       "      <td>35.035000</td>\n",
       "      <td>74.809930</td>\n",
       "      <td>25.190073</td>\n",
       "      <td>60.211590</td>\n",
       "      <td>39.788406</td>\n",
       "      <td>28.860714</td>\n",
       "      <td>26.783783</td>\n",
       "      <td>22.543377</td>\n",
       "      <td>29.639566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1.30</td>\n",
       "      <td>110</td>\n",
       "      <td>90</td>\n",
       "      <td>-5</td>\n",
       "      <td>270</td>\n",
       "      <td>0.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>26.953548</td>\n",
       "      <td>27.834307</td>\n",
       "      <td>59.529460</td>\n",
       "      <td>40.470543</td>\n",
       "      <td>75.384056</td>\n",
       "      <td>24.615942</td>\n",
       "      <td>27.605902</td>\n",
       "      <td>38.423260</td>\n",
       "      <td>36.216520</td>\n",
       "      <td>28.687640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>1.05</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "      <td>-5</td>\n",
       "      <td>250</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16.746920</td>\n",
       "      <td>37.435730</td>\n",
       "      <td>63.826660</td>\n",
       "      <td>36.173336</td>\n",
       "      <td>81.396390</td>\n",
       "      <td>18.603607</td>\n",
       "      <td>33.057850</td>\n",
       "      <td>29.942450</td>\n",
       "      <td>34.096320</td>\n",
       "      <td>31.240532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>1.00</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>-5</td>\n",
       "      <td>280</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>16.090190</td>\n",
       "      <td>35.037178</td>\n",
       "      <td>65.989174</td>\n",
       "      <td>34.010830</td>\n",
       "      <td>76.243580</td>\n",
       "      <td>23.756414</td>\n",
       "      <td>37.038640</td>\n",
       "      <td>29.120335</td>\n",
       "      <td>27.000130</td>\n",
       "      <td>39.115574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 91 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 229
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "source": [
    "loaded_model.get_booster().get_score(importance_type='weight')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Booster' object has no attribute 'get_booster'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-236-63a734d85fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_booster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'get_booster'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "def create_frame_from_jsonv2(json_stats):\n",
    "    df = pd.DataFrame.from_dict(json_stats)\n",
    "    df['core'] = df.stats.apply(lambda x:x['core'])\n",
    "    df['boost'] = df.stats.apply(lambda x:x['boost'])\n",
    "    df['movement'] = df.stats.apply(lambda x:x['movement'])\n",
    "    df['positioning'] = df.stats.apply(lambda x:x['positioning'])\n",
    "    df['demo'] = df.stats.apply(lambda x:x['demo'])\n",
    "    df['mvp'] = df.mvp.apply(lambda x: 1 if x==True else 0)\n",
    "    camera_keys = list(df.iloc[0]['camera'].keys())\n",
    "    core_stats_keys = list(df.iloc[0]['stats']['core'].keys())\n",
    "    boost_keys = list(df.iloc[0]['stats']['boost'].keys())\n",
    "    movement_keys = list(df.iloc[0]['stats']['movement'].keys())\n",
    "    positioning_keys = ['avg_distance_to_ball', 'avg_distance_to_ball_possession',\n",
    "        'avg_distance_to_ball_no_possession', 'avg_distance_to_mates',\n",
    "        'time_defensive_third', 'time_neutral_third', 'time_offensive_third',\n",
    "        'time_defensive_half', 'time_offensive_half', 'time_behind_ball',\n",
    "        'time_infront_ball', 'time_most_back', 'time_most_forward',\n",
    "        'time_closest_to_ball', 'time_farthest_from_ball',\n",
    "        'percent_defensive_third', 'percent_offensive_third',\n",
    "        'percent_neutral_third', 'percent_defensive_half',\n",
    "        'percent_offensive_half', 'percent_behind_ball', 'percent_infront_ball',\n",
    "        'percent_most_back', 'percent_most_forward', 'percent_closest_to_ball',\n",
    "        'percent_farthest_from_ball']\n",
    "    demo_keys = list(df.iloc[0]['stats']['demo'].keys())\n",
    "    df[camera_keys] = pd.json_normalize(df['camera'])\n",
    "    df[core_stats_keys] = pd.json_normalize(df['core'])\n",
    "    df[boost_keys] = pd.json_normalize(df['boost'])\n",
    "    df[movement_keys] = pd.json_normalize(df['movement'])\n",
    "    df[demo_keys] = pd.json_normalize(df['demo'])\n",
    "\n",
    "    df['positioning'] = df.stats.apply(lambda x: remove_extra_element(x['positioning']))\n",
    "    df[positioning_keys] = pd.json_normalize(df['positioning'])\n",
    "    names = df['name']\n",
    "    df = df.drop(['camera', 'stats', 'camera', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'id', 'name', 'car_id', 'car_name', 'rank'], axis=1)\n",
    "    return df, names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}