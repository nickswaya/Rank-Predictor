{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
   }
  },
  "interpreter": {
   "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from random import randrange, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from helper import *\n",
    "import math\n",
    "import logging\n",
    "from retrying import retry\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "r = requests.get('https://ballchasing.com/api/replays?player-name=LebaneseNinja&player-id=steam:76561198068157523&count=200&playlist=ranked-standard', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "d=r.json()\n",
    "math.floor(d['count']/200)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "source": [
    "d['list'][0].keys()\n",
    "replay_ids = []\n",
    "for i in range(200):\n",
    "    replay_ids.append(d['list'][i]['id'])\n",
    "replay_ids[0:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['cb863170-3ccf-49f2-b39b-0b54c59d94ba',\n",
       " '7e0329db-07c7-4467-9cb2-1aa3c7914954',\n",
       " 'c7efa15d-abbc-44cc-9ea6-afd0cca0a456',\n",
       " '12f55fcf-f619-4687-8956-c418de950adc',\n",
       " '8305a131-70f8-4cbf-9022-c4cb00904c66']"
      ]
     },
     "metadata": {},
     "execution_count": 367
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "orange_ranks = []\n",
    "orange_stats = []\n",
    "blue_ranks = []\n",
    "blue_stats = []\n",
    "for replay_id in replay_ids:\n",
    "    replay_stats = requests.get(f'https://ballchasing.com/api/replays/{replay_id}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "    test_stats = replay_stats.json()\n",
    "    try:\n",
    "        ranks = [test_stats['orange']['players'][player]['rank']['name'] for player in range(3)]\n",
    "        orange_ranks.append(ranks)\n",
    "        stats = [test_stats['orange']['players'][player] for player in range(3)]\n",
    "        orange_stats.append(stats[0])\n",
    "        orange_stats.append(stats[1])\n",
    "        orange_stats.append(stats[2])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ranks = [test_stats['blue']['players'][player]['rank']['name'] for player in range(3)]\n",
    "        blue_ranks.append(ranks)\n",
    "        stats = [test_stats['blue']['players'][player] for player in range(3)]\n",
    "        blue_stats.append(stats[0])\n",
    "        blue_stats.append(stats[1])\n",
    "        blue_stats.append(stats[2])\n",
    "    except:\n",
    "        pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "source": [
    "def remove_extra_element(row):\n",
    "    if 'goals_against_while_last_defender' in row:\n",
    "        del row['goals_against_while_last_defender']\n",
    "    return row\n",
    "\n",
    "orange_df = pd.DataFrame.from_dict(orange_stats)\n",
    "\n",
    "orange_df['core'] = orange_df.stats.apply(lambda x:x['core'])\n",
    "orange_df['boost'] = orange_df.stats.apply(lambda x:x['boost'])\n",
    "orange_df['movement'] = orange_df.stats.apply(lambda x:x['movement'])\n",
    "orange_df['positioning'] = orange_df.stats.apply(lambda x:x['positioning'])\n",
    "orange_df['demo'] = orange_df.stats.apply(lambda x:x['demo'])\n",
    "\n",
    "\n",
    "rank_keys = list(orange_stats[0]['rank'].keys())\n",
    "camera_keys = list(orange_stats[0]['camera'].keys())\n",
    "core_stats_keys = list(orange_stats[0]['stats']['core'].keys())\n",
    "boost_keys = list(orange_stats[0]['stats']['boost'].keys())\n",
    "movement_keys = list(orange_stats[0]['stats']['movement'].keys())\n",
    "positioning_keys = ['avg_distance_to_ball', 'avg_distance_to_ball_possession',\n",
    "       'avg_distance_to_ball_no_possession', 'avg_distance_to_mates',\n",
    "       'time_defensive_third', 'time_neutral_third', 'time_offensive_third',\n",
    "       'time_defensive_half', 'time_offensive_half', 'time_behind_ball',\n",
    "       'time_infront_ball', 'time_most_back', 'time_most_forward',\n",
    "       'time_closest_to_ball', 'time_farthest_from_ball',\n",
    "       'percent_defensive_third', 'percent_offensive_third',\n",
    "       'percent_neutral_third', 'percent_defensive_half',\n",
    "       'percent_offensive_half', 'percent_behind_ball', 'percent_infront_ball',\n",
    "       'percent_most_back', 'percent_most_forward', 'percent_closest_to_ball',\n",
    "       'percent_farthest_from_ball']\n",
    "demo_keys = list(orange_stats[0]['stats']['demo'].keys())\n",
    "\n",
    "\n",
    "orange_df[rank_keys] = pd.json_normalize(orange_df['rank'])\n",
    "orange_df[camera_keys] = pd.json_normalize(orange_df['camera'])\n",
    "orange_df[core_stats_keys] = pd.json_normalize(orange_df['core'])\n",
    "orange_df[boost_keys] = pd.json_normalize(orange_df['boost'])\n",
    "orange_df[movement_keys] = pd.json_normalize(orange_df['movement'])\n",
    "orange_df[demo_keys] = pd.json_normalize(orange_df['demo'])\n",
    "\n",
    "orange_df['positioning'] = orange_df.stats.apply(lambda x: remove_extra_element(x['positioning']))\n",
    "orange_df[positioning_keys] = pd.json_normalize(orange_df['positioning'])\n",
    "\n",
    "orange_df = orange_df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo'], axis=1)\n",
    "\n",
    "\n",
    "def create_frame_from_json(json_stats, rank_target):\n",
    "    df = pd.DataFrame.from_dict(json_stats)\n",
    "\n",
    "    df['core'] = df.stats.apply(lambda x:x['core'])\n",
    "    df['boost'] = df.stats.apply(lambda x:x['boost'])\n",
    "    df['movement'] = df.stats.apply(lambda x:x['movement'])\n",
    "    df['positioning'] = df.stats.apply(lambda x:x['positioning'])\n",
    "    df['demo'] = df.stats.apply(lambda x:x['demo'])\n",
    "    \n",
    "\n",
    "    rank_keys = list(df.iloc[0]['rank'].keys())\n",
    "    camera_keys = list(df.iloc[0]['camera'].keys())\n",
    "    core_stats_keys = list(df.iloc[0]['stats']['core'].keys())\n",
    "    boost_keys = list(df.iloc[0]['stats']['boost'].keys())\n",
    "    movement_keys = list(df.iloc[0]['stats']['movement'].keys())\n",
    "    positioning_keys = ['avg_distance_to_ball', 'avg_distance_to_ball_possession',\n",
    "        'avg_distance_to_ball_no_possession', 'avg_distance_to_mates',\n",
    "        'time_defensive_third', 'time_neutral_third', 'time_offensive_third',\n",
    "        'time_defensive_half', 'time_offensive_half', 'time_behind_ball',\n",
    "        'time_infront_ball', 'time_most_back', 'time_most_forward',\n",
    "        'time_closest_to_ball', 'time_farthest_from_ball',\n",
    "        'percent_defensive_third', 'percent_offensive_third',\n",
    "        'percent_neutral_third', 'percent_defensive_half',\n",
    "        'percent_offensive_half', 'percent_behind_ball', 'percent_infront_ball',\n",
    "        'percent_most_back', 'percent_most_forward', 'percent_closest_to_ball',\n",
    "        'percent_farthest_from_ball']\n",
    "    demo_keys = list(df.iloc[0]['stats']['demo'].keys())\n",
    "\n",
    "    df[rank_keys] = pd.json_normalize(df['rank'])\n",
    "    df[camera_keys] = pd.json_normalize(df['camera'])\n",
    "    df[core_stats_keys] = pd.json_normalize(df['core'])\n",
    "    df[boost_keys] = pd.json_normalize(df['boost'])\n",
    "    df[movement_keys] = pd.json_normalize(df['movement'])\n",
    "    df[demo_keys] = pd.json_normalize(df['demo'])\n",
    "\n",
    "    df['positioning'] = df.stats.apply(lambda x: remove_extra_element(x['positioning']))\n",
    "    df[positioning_keys] = pd.json_normalize(df['positioning'])\n",
    "    if rank_target == 'tier_div':\n",
    "        df['rank_target'] = df['tier'] * 4 + df['division']\n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df\n",
    "    if rank_target == 'tier':\n",
    "        df['rank_target'] = df['id'] \n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "source": [
    "scores = []\n",
    "\n",
    "for i in range(10):\n",
    "    blue_df = create_frame_from_json(blue_stats, 'tier_div')\n",
    "    orange_df = create_frame_from_json(orange_stats, 'tier_div')\n",
    "    df = combine_clean_dfs(blue_df, orange_df, car_dummies=False)\n",
    "    y = df.pop('rank_target')\n",
    "    X = df\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33, random_state=0)\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(X_train, y_train)\n",
    "    scores.append(rf.score(X_test, y_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "source": [
    "r = requests.get('https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "d = r.json()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "scores = defaultdict(list)\n",
    "names = X.columns\n",
    "feature_importances = np.argsort(rf.feature_importances_)\n",
    "print(\"top five:\", list(X.columns[feature_importances[-1:-6:-1]]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "top five: ['avg_distance_to_ball_no_possession', 'percent_neutral_third', 'avg_distance_to_mates', 'percent_defensive_third', 'amount_used_while_supersonic']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = list(X_train.columns[indices])\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[f], importances[indices[f]]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Feature ranking:\n",
      "1. avg_distance_to_ball_no_possession (0.081882)\n",
      "2. percent_neutral_third (0.064356)\n",
      "3. avg_distance_to_mates (0.033241)\n",
      "4. percent_defensive_third (0.028744)\n",
      "5. amount_used_while_supersonic (0.028155)\n",
      "6. score (0.027391)\n",
      "7. amount_stolen (0.025814)\n",
      "8. percent_most_back (0.024448)\n",
      "9. percent_zero_boost (0.019028)\n",
      "10. percent_closest_to_ball (0.018262)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "kf = KFold(10)\n",
    "rf_pipe = Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier())])\n",
    "rf_grid_params = {'classifier__max_depth': np.arange(1, 20)}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'accuracy')\n",
    "rf_grid.fit(X_train, y_train) # fill in later in lecture\n",
    "\n",
    "print(\"Random Forest Testing Accuracy: {}\".format(rf_grid.score(X_test, y_test)))\n",
    "\n",
    "rf_grid.best_estimator_"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Random Forest Testing Accuracy: 0.18120805369127516\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier', RandomForestClassifier(max_depth=16))])"
      ]
     },
     "metadata": {},
     "execution_count": 177
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "source": [
    "def get_all_ids():\n",
    "    season_lst = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','f1', 'f2', 'f3', 'f4']\n",
    "    replay_ids = []\n",
    "    for i in range(len(season_lst)):\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?player-name=LebaneseNinja&player-id=steam:76561198068157523&count=200&playlist=ranked-standard&season={season_lst[i]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        replay_ids.append(rank_ids)\n",
    "    return replay_ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "source": [
    "replay_ids = get_all_ids()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "source": [
    "flat_list = [item for sublist in replay_ids for item in sublist]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def get_stats_from_replays(replay_ids):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "\n",
    "    orange_ranks = []\n",
    "    orange_stats = []\n",
    "    blue_ranks = []\n",
    "    blue_stats = []\n",
    "    pull_num = 0\n",
    "    for replay_id in replay_ids:\n",
    "        replay_stats = requests.get(f'https://ballchasing.com/api/replays/{replay_id}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        test_stats = replay_stats.json()\n",
    "        try:\n",
    "            ranks = [test_stats['orange']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            orange_ranks.append(ranks)\n",
    "            stats = [test_stats['orange']['players'][player] for player in range(3)]\n",
    "            orange_stats.append(stats[0])\n",
    "            orange_stats.append(stats[1])\n",
    "            orange_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ranks = [test_stats['blue']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            blue_ranks.append(ranks)\n",
    "            stats = [test_stats['blue']['players'][player] for player in range(3)]\n",
    "            blue_stats.append(stats[0])\n",
    "            blue_stats.append(stats[1])\n",
    "            blue_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        pull_num += 1\n",
    "        logger.info(f'stats extracted for pull num {pull_num}')\n",
    "        \n",
    "    return blue_stats, orange_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "source": [
    "blue_stats, orange_stats = get_stats_from_replays(flat_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "source": [
    "blue_df_2 = create_frame_from_json(blue_stats, 'tier')\n",
    "orange_df_2 = create_frame_from_json(orange_stats, 'tier')\n",
    "\n",
    "def combine_clean_dfs(blue_df, orange_df, car_dummies):\n",
    "    combined_dfs = blue_df.append(orange_df)\n",
    "    combined_dfs['mvp'] = combined_dfs.mvp.apply(lambda x: 1 if x==True else 0)\n",
    "\n",
    "    if car_dummies == False:\n",
    "        combined_dfs = combined_dfs.drop('car_name', axis=1)\n",
    "        return combined_dfs\n",
    "    if car_dummies == True:\n",
    "        dummies = pd.get_dummies(combined_dfs.car_name, drop_first=True)\n",
    "        combined_concat_w_dummies = pd.concat([combined_dfs, dummies], axis=1)\n",
    "        combined_concat_w_dummies = combined_concat_w_dummies.drop('car_name', axis=1)\n",
    "        return combined_concat_w_dummies\n",
    "    \n",
    "combined_df_2 = combine_clean_dfs(blue_df_2, orange_df_2, car_dummies=True)\n",
    "combined_df_2 = combined_df_2.reset_index(drop=True)\n",
    "\n",
    "y = combined_df_2.pop('rank_target')\n",
    "X = combined_df_2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "scores = defaultdict(list)\n",
    "names = X.columns\n",
    "feature_importances = np.argsort(rf.feature_importances_)\n",
    "print(\"top five:\", list(X.columns[feature_importances[-1:-6:-1]]))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = list(X_train.columns[indices])\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[f], importances[indices[f]]))\n",
    "\n",
    "\n",
    "kf = KFold(10)\n",
    "rf_pipe = Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier())])\n",
    "rf_grid_params = {'classifier__max_depth': np.arange(1, 20)}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'accuracy')\n",
    "rf_grid.fit(X_train, y_train) # fill in later in lecture\n",
    "\n",
    "print(\"Random Forest Testing Accuracy: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "source": [
    "blue_df_2 = create_frame_from_json(blue_stats, 'tier')\n",
    "orange_df_2 = create_frame_from_json(orange_stats, 'tier')\n",
    "c = combine_clean_dfs(blue_df_2, orange_df_2)\n",
    "\n",
    "y = c.pop('rank_target')\n",
    "X = c\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.33,\n",
    "                                                    random_state=0)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "metadata": {},
     "execution_count": 275
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "source": [
    "rf.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.14692569062974747"
      ]
     },
     "metadata": {},
     "execution_count": 316
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "source": [
    "c = combine_clean_dfs(blue_df_2, orange_df_2, car_dummies=False)\n",
    "\n",
    "y = c.pop('rank_target')\n",
    "X = c\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33,random_state=0)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.30869565217391304"
      ]
     },
     "metadata": {},
     "execution_count": 288
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def get_random_ids():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "    logger.info('starting pull')\n",
    "    minmax_rank_lst = [['bronze-1', 'bronze-3'], ['silver-1', 'silver-3'], ['gold-1', 'gold-3'], ['platinum-1', 'platinum-3'], ['diamond-1', 'diamond-3'], ['champion-1', 'champion-3'], ['champion-3', 'grand-champion']]\n",
    "    replay_ids = []\n",
    "    ids_pulled = []\n",
    "    for i in range(len(minmax_rank_lst)):\n",
    "        logger.info(f'pulling min_rank={minmax_rank_lst[i][0]}, max_rank = {minmax_rank_lst[i][1]}')\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard&min-rank={minmax_rank_lst[i][0]}&max-rank={minmax_rank_lst[i][1]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        count = d['count']\n",
    "        logger.info(f'count = {count}')\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "        if i == 6 or i == 5:\n",
    "            logger.info('i == 5 or 6, moving on')\n",
    "            replay_ids.append(rank_ids)\n",
    "            continue \n",
    "\n",
    "        logger.info('starting second pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "\n",
    "        logger.info('starting third pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        logger.info('rank pull complete.. appending results and moving to next rank') \n",
    "        replay_ids.append(rank_ids)\n",
    "\n",
    "    flat_list = [item for sublist in replay_ids for item in sublist]\n",
    "    return flat_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "random_matches = get_random_ids()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "res = []\n",
    "[res.append(x) for x in random_matches if x not in res]\n",
    "\n",
    "blue_stats, orange_stats = get_stats_from_replays(res)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "blue_df2 = create_frame_from_json(blue_stats, rank_target='tier_div')\n",
    "orange_df2 = create_frame_from_json(orange_stats, rank_target='tier_div')\n",
    "full_df_dummies = combine_clean_dfs(blue_df2, orange_df2, car_dummies=True)\n",
    "full_df_nodummies = combine_clean_dfs(blue_df2, orange_df2, car_dummies=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "full_df_nodummies = full_df_nodummies.dropna(axis=0)\n",
    "\n",
    "y = full_df_nodummies.pop('rank_target')\n",
    "X = full_df_nodummies\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33,random_state=0)\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "scores = defaultdict(list)\n",
    "names = X.columns\n",
    "feature_importances = np.argsort(rf.feature_importances_)\n",
    "print(\"top five:\", list(X.columns[feature_importances[-1:-6:-1]]))\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = list(X_train.columns[indices])\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(10):\n",
    "    print(\"%d. %s (%f)\" % (f + 1, features[f], importances[indices[f]]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "top five: ['count_powerslide', 'bcpm', 'avg_distance_to_mates', 'percent_high_air', 'avg_powerslide_duration']\n",
      "Feature ranking:\n",
      "1. count_powerslide (0.302556)\n",
      "2. bcpm (0.182415)\n",
      "3. avg_distance_to_mates (0.121159)\n",
      "4. percent_high_air (0.038722)\n",
      "5. avg_powerslide_duration (0.033754)\n",
      "6. avg_speed (0.014845)\n",
      "7. avg_speed_percentage (0.012625)\n",
      "8. bpm (0.012485)\n",
      "9. amount_used_while_supersonic (0.009975)\n",
      "10. percent_ground (0.008628)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "kf = KFold(10)\n",
    "rf_pipe = Pipeline([('scaler', StandardScaler()), ('classifier', RandomForestClassifier())])\n",
    "rf_grid_params = {'classifier__max_depth': np.arange(10, 20)}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'accuracy')\n",
    "rf_grid.fit(X_train, y_train) \n",
    "\n",
    "print(\"Random Forest Testing Accuracy: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}