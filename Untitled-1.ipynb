{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
   }
  },
  "interpreter": {
   "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from random import randrange, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from helper import *\n",
    "import math\n",
    "import logging\n",
    "from retrying import retry\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from itertools import islice\n",
    "from sklearn.ensemble import (GradientBoostingRegressor, GradientBoostingClassifier, AdaBoostClassifier,RandomForestClassifier)\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pylab import rcParams\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('ggplot')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d['list'][0].keys()\n",
    "replay_ids = []\n",
    "for i in range(200):\n",
    "    replay_ids.append(d['list'][i]['id'])\n",
    "replay_ids[0:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def remove_extra_element(row):\n",
    "    if 'goals_against_while_last_defender' in row:\n",
    "        del row['goals_against_while_last_defender']\n",
    "    return row\n",
    "\n",
    "\n",
    "def create_frame_from_json(json_stats, rank_target):\n",
    "    df = pd.DataFrame.from_dict(json_stats)\n",
    "\n",
    "    df['core'] = df.stats.apply(lambda x:x['core'])\n",
    "    df['boost'] = df.stats.apply(lambda x:x['boost'])\n",
    "    df['movement'] = df.stats.apply(lambda x:x['movement'])\n",
    "    df['positioning'] = df.stats.apply(lambda x:x['positioning'])\n",
    "    df['demo'] = df.stats.apply(lambda x:x['demo'])\n",
    "    \n",
    "\n",
    "    rank_keys = list(df.iloc[0]['rank'].keys())\n",
    "    camera_keys = list(df.iloc[0]['camera'].keys())\n",
    "    core_stats_keys = list(df.iloc[0]['stats']['core'].keys())\n",
    "    boost_keys = list(df.iloc[0]['stats']['boost'].keys())\n",
    "    movement_keys = list(df.iloc[0]['stats']['movement'].keys())\n",
    "    positioning_keys = ['avg_distance_to_ball', 'avg_distance_to_ball_possession',\n",
    "        'avg_distance_to_ball_no_possession', 'avg_distance_to_mates',\n",
    "        'time_defensive_third', 'time_neutral_third', 'time_offensive_third',\n",
    "        'time_defensive_half', 'time_offensive_half', 'time_behind_ball',\n",
    "        'time_infront_ball', 'time_most_back', 'time_most_forward',\n",
    "        'time_closest_to_ball', 'time_farthest_from_ball',\n",
    "        'percent_defensive_third', 'percent_offensive_third',\n",
    "        'percent_neutral_third', 'percent_defensive_half',\n",
    "        'percent_offensive_half', 'percent_behind_ball', 'percent_infront_ball',\n",
    "        'percent_most_back', 'percent_most_forward', 'percent_closest_to_ball',\n",
    "        'percent_farthest_from_ball']\n",
    "    demo_keys = list(df.iloc[0]['stats']['demo'].keys())\n",
    "\n",
    "    df[rank_keys] = pd.json_normalize(df['rank'])\n",
    "    df[camera_keys] = pd.json_normalize(df['camera'])\n",
    "    df[core_stats_keys] = pd.json_normalize(df['core'])\n",
    "    df[boost_keys] = pd.json_normalize(df['boost'])\n",
    "    df[movement_keys] = pd.json_normalize(df['movement'])\n",
    "    df[demo_keys] = pd.json_normalize(df['demo'])\n",
    "\n",
    "    df['positioning'] = df.stats.apply(lambda x: remove_extra_element(x['positioning']))\n",
    "    df[positioning_keys] = pd.json_normalize(df['positioning'])\n",
    "    if rank_target == 'tier_div':\n",
    "        df['rank_target'] = df['tier'] * 4 + df['division']\n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df\n",
    "    if rank_target == 'tier':\n",
    "        df['rank_target'] = df['id'] \n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_all_ids():\n",
    "    season_lst = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','f1', 'f2', 'f3', 'f4']\n",
    "    replay_ids = []\n",
    "    for i in range(len(season_lst)):\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?player-name=LebaneseNinja&player-id=steam:76561198068157523&count=200&playlist=ranked-standard&season={season_lst[i]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        replay_ids.append(rank_ids)\n",
    "    return replay_ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stats_from_replays(replay_ids):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "\n",
    "    orange_ranks = []\n",
    "    orange_stats = []\n",
    "    blue_ranks = []\n",
    "    blue_stats = []\n",
    "    pull_num = 0\n",
    "    for replay_id in replay_ids:\n",
    "        replay_stats = requests.get(f'https://ballchasing.com/api/replays/{replay_id}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        test_stats = replay_stats.json()\n",
    "        try:\n",
    "            ranks = [test_stats['orange']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            orange_ranks.append(ranks)\n",
    "            stats = [test_stats['orange']['players'][player] for player in range(3)]\n",
    "            orange_stats.append(stats[0])\n",
    "            orange_stats.append(stats[1])\n",
    "            orange_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ranks = [test_stats['blue']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            blue_ranks.append(ranks)\n",
    "            stats = [test_stats['blue']['players'][player] for player in range(3)]\n",
    "            blue_stats.append(stats[0])\n",
    "            blue_stats.append(stats[1])\n",
    "            blue_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        pull_num += 1\n",
    "        logger.info(f'stats extracted for pull num {pull_num}')\n",
    "        \n",
    "    return blue_stats, orange_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def combine_clean_dfs(blue_df, orange_df, car_dummies):\n",
    "    combined_dfs = blue_df.append(orange_df)\n",
    "    combined_dfs['mvp'] = combined_dfs.mvp.apply(lambda x: 1 if x==True else 0)\n",
    "\n",
    "    if car_dummies == False:\n",
    "        combined_dfs = combined_dfs.drop('car_name', axis=1)\n",
    "        return combined_dfs\n",
    "    if car_dummies == True:\n",
    "        dummies = pd.get_dummies(combined_dfs.car_name, drop_first=True)\n",
    "        combined_concat_w_dummies = pd.concat([combined_dfs, dummies], axis=1)\n",
    "        combined_concat_w_dummies = combined_concat_w_dummies.drop('car_name', axis=1)\n",
    "        return combined_concat_w_dummies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_random_ids():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "    logger.info('starting pull')\n",
    "    minmax_rank_lst = [['bronze-1', 'bronze-3'], ['silver-1', 'silver-3'], ['gold-1', 'gold-3'], ['platinum-1', 'platinum-3'], ['diamond-1', 'diamond-3'], ['champion-1', 'champion-3'], ['champion-3', 'grand-champion']]\n",
    "    replay_ids = []\n",
    "    ids_pulled = []\n",
    "    for i in range(len(minmax_rank_lst)):\n",
    "        logger.info(f'pulling min_rank={minmax_rank_lst[i][0]}, max_rank = {minmax_rank_lst[i][1]}')\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard&min-rank={minmax_rank_lst[i][0]}&max-rank={minmax_rank_lst[i][1]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        count = d['count']\n",
    "        logger.info(f'count = {count}')\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "        if i == 6 or i == 5:\n",
    "            logger.info('i == 5 or 6, moving on')\n",
    "            replay_ids.append(rank_ids)\n",
    "            continue \n",
    "\n",
    "        logger.info('starting second pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "\n",
    "        logger.info('starting third pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        logger.info('rank pull complete.. appending results and moving to next rank') \n",
    "        replay_ids.append(rank_ids)\n",
    "\n",
    "    flat_list = [item for sublist in replay_ids for item in sublist]\n",
    "    return flat_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('full_nodummies.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "y = df.pop('rank_target')\n",
    "X = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "kf = KFold(10)\n",
    "rf_pipe = Pipeline([('classifier', GradientBoostingRegressor())])\n",
    "rf_grid_params = {'classifier__max_features': ['sqrt', 'log2'], 'classifier__n_estimators': [900, 1000, 1100]}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'neg_mean_absolute_error')\n",
    "rf_grid.fit(X_train, y_train) \n",
    "print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))\n",
    "\n",
    "'''\n",
    "best estimator : [('classifier',\n",
    "                 GradientBoostingRegressor(max_features='sqrt',\n",
    "                                           n_estimators=900))])\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "axs = axs.flatten()\n",
    "axs[0].hist(y_train)\n",
    "axs[0].set_title('y_train rank distribution')\n",
    "axs[0].set_ylabel('count')\n",
    "axs[0].set_xlabel('rank target')\n",
    "axs[1].hist(y_test)\n",
    "axs[1].set_title('y_test rank distribution')\n",
    "axs[1].set_ylabel('count')\n",
    "axs[1].set_xlabel('rank target');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "keras = tf.keras\n",
    "\n",
    "NN_model = keras.models.Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(keras.layers.Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(45, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split = 0.2)\n",
    "'''\n",
    "224/224 [==============================] - 0s 831us/step - loss: 7.2956 - mean_absolute_error: 7.2956 - val_loss: 7.2235 - val_mean_absolute_error: 7.2235\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_all():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "    logger.info('starting pull')\n",
    "    minmax_rank_lst = [['champion-1', 'champion-3'], ['champion-3', 'grand-champion']]\n",
    "    replay_ids = []\n",
    "    ids_pulled = []\n",
    "    for i in range(len(minmax_rank_lst)):\n",
    "        logger.info(f'pulling min_rank={minmax_rank_lst[i][0]}, max_rank = {minmax_rank_lst[i][1]}')\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard&min-rank={minmax_rank_lst[i][0]}&max-rank={minmax_rank_lst[i][1]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        count = d['count']\n",
    "        next_link = d['next']\n",
    "        logger.info(f'count = {count}')\n",
    "        for pull in range(math.floor(count/200)-2):\n",
    "            logger.info(f'starting pull number {pull+1}')\n",
    "            r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "            d = r.json()\n",
    "            try:\n",
    "                for i in range(len(d['list'])):\n",
    "                    rank_ids.append(d['list'][i]['id'])\n",
    "            except:\n",
    "                pass\n",
    "            next_link = d['next']\n",
    "        logger.info('rank pull complete.. appending results, saving series and moving to next rank') \n",
    "        replay_ids.append(rank_ids)\n",
    "        match_ids_tosave = pd.Series(replay_ids)\n",
    "        match_ids_tosave.to_csv('test_pull_all_ids.csv')\n",
    "    flat_list = [item for sublist in replay_ids for item in sublist]\n",
    "    return flat_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "up_to_d1 = pd.read_csv('up_to_diamond1.csv')\n",
    "d1uptochamp = pd.read_csv('diamond1_uptochamp1.csv')\n",
    "champtogc = pd.read_csv('champ_to_gc.csv')\n",
    "\n",
    "\n",
    "d1uptochampa = d1uptochamp.iloc[0]['0']\n",
    "da = d1uptochampa.split(',')\n",
    "da = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in da]\n",
    "\n",
    "\n",
    "champtogca = champtogc.iloc[0]['0']\n",
    "gca = champtogca.split(',')\n",
    "gca = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in gca]\n",
    "\n",
    "champtogcb = champtogc.iloc[1]['0']\n",
    "gcb = champtogcb.split(',')\n",
    "gcb = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in gcb]\n",
    "\n",
    "\n",
    "up_to_d1_a = up_to_d1.iloc[0]['0']\n",
    "a = up_to_d1_a.split(',')\n",
    "a = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in a]\n",
    "\n",
    "up_to_d1_b = up_to_d1.iloc[1]['0']\n",
    "b = up_to_d1_b.split(',')\n",
    "b = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in b]\n",
    "\n",
    "up_to_d1_c = up_to_d1.iloc[2]['0']\n",
    "c = up_to_d1_c.split(',')\n",
    "c = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in c]\n",
    "\n",
    "up_to_d1_d = up_to_d1.iloc[3]['0']\n",
    "d = up_to_d1_d.split(',')\n",
    "d = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in d]\n",
    "\n",
    "res = []\n",
    "res.append(a)\n",
    "res.append(b)\n",
    "res.append(c)\n",
    "res.append(d)\n",
    "res.append(da)\n",
    "res.append(gca)\n",
    "res.append(gcb)\n",
    "\n",
    "flat_list = [item for sublist in res for item in sublist]\n",
    "res1 = []\n",
    "for i in flat_list:\n",
    "    if i not in res1:\n",
    "        res1.append(i)\n",
    "res1 = [i.replace(' ', '') for i in res1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'27,095'\n",
    "blue_stats, orange_stats = get_stats_from_replays(res1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "blue_df = create_frame_from_json(blue_stats, 'tier_div')\n",
    "orange_df = create_frame_from_json(orange_stats, 'tier_div')\n",
    "full_df = combine_clean_dfs(blue_df, orange_df, car_dummies=False)\n",
    "full_df = full_df.dropna()\n",
    "full_df.to_csv('final_full_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "\n",
    "train, holdout = train_test_split(X, y)\n",
    "holdout_y = holdout.pop('rank_target')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "\n",
    "keras = tf.keras\n",
    "\n",
    "NN_model = keras.models.Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(keras.layers.Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(45, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split = 0.2)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "mean_train = np.mean(y_train)\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))\n",
    "\n",
    "'''\n",
    "Baseline MAE is 7.85\n",
    "'''\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "params['eval_metric'] = \"mae\"\n",
    "num_boost_round = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# kf = KFold(10)\n",
    "# rf_pipe = Pipeline([('classifier', GradientBoostingRegressor())])\n",
    "# rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'neg_mean_absolute_error')\n",
    "# rf_grid.fit(X_train, y_train) \n",
    "# print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
       "0         49.529891       0.014215      49.535730      0.066456\n",
       "1         34.686686       0.009014      34.697300      0.054243\n",
       "2         24.321538       0.005372      24.338942      0.045971\n",
       "3         17.188786       0.003156      17.237071      0.035732\n",
       "4         12.425538       0.002522      12.508940      0.026652\n",
       "..              ...            ...            ...           ...\n",
       "103        3.815101       0.020812       5.182862      0.031506\n",
       "104        3.806403       0.019497       5.182730      0.031552\n",
       "105        3.799121       0.017021       5.182864      0.031522\n",
       "106        3.790143       0.016081       5.182227      0.031588\n",
       "107        3.782442       0.015794       5.182021      0.031929\n",
       "\n",
       "[108 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.529891</td>\n",
       "      <td>0.014215</td>\n",
       "      <td>49.535730</td>\n",
       "      <td>0.066456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.686686</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>34.697300</td>\n",
       "      <td>0.054243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.321538</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>24.338942</td>\n",
       "      <td>0.045971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.188786</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>17.237071</td>\n",
       "      <td>0.035732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.425538</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>12.508940</td>\n",
       "      <td>0.026652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>3.815101</td>\n",
       "      <td>0.020812</td>\n",
       "      <td>5.182862</td>\n",
       "      <td>0.031506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3.806403</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>5.182730</td>\n",
       "      <td>0.031552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3.799121</td>\n",
       "      <td>0.017021</td>\n",
       "      <td>5.182864</td>\n",
       "      <td>0.031522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3.790143</td>\n",
       "      <td>0.016081</td>\n",
       "      <td>5.182227</td>\n",
       "      <td>0.031588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3.782442</td>\n",
       "      <td>0.015794</td>\n",
       "      <td>5.182021</td>\n",
       "      <td>0.031929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 191
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "cv_results['test-mae-mean'].min()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.1820208"
      ]
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best MAE\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tMAE 5.187220399999999 for 564 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMAE 5.1921274 for 509 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMAE 5.2249106 for 117 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMAE 5.205360600000001 for 508 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMAE 5.190863599999999 for 470 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMAE 5.194477999999999 for 557 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMAE 5.2304981999999995 for 498 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMAE 5.2209956 for 375 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMAE 5.2162896000000005 for 350 rounds\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "full_df = full_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train, holdout = train_test_split(full_df, test_size=0.2)\n",
    "\n",
    "label = np.array(train.pop('rank_target'))\n",
    "X = np.array(train)\n",
    "dtrain = xgb.DMatrix(X, label=label)\n",
    "\n",
    "holdout_label = np.array(holdout.pop('rank_target'))\n",
    "holdout_X = np.array(holdout)\n",
    "holdout_dtest = xgb.DMatrix(holdout_X, label=holdout_label)\n",
    "\n",
    "\n",
    "param = {'eval_metric': 'mae'}\n",
    "param['nthread'] = 6\n",
    "evallist = [(dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param, dtrain, 20,  evallist)\n",
    "ypred = bst.predict(holdout_dtest)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "kf = KFold(10)\n",
    "params = {'classifier__objective': ['reg:squarederror'], 'classifier__max_depth': np.linspace(2, 12, 6).astype(int), 'classifier__n_estimators': np.linspace(30,600,7).astype(int), 'classifier__n_jobs': [6], }\n",
    "rf_pipe = Pipeline([('classifier', xgb.XGBRegressor())])\n",
    "rf_grid = GridSearchCV(rf_pipe, param_grid = params, cv=kf)\n",
    "rf_grid.fit(X_train, y_train) \n",
    "print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rf_pipe = Pipeline([('classifier', xgb.XGBRegressor())])\n",
    "params = {'classifier__objective': 'reg:squarederror', 'eval_metric': 'mae', 'classifier__max_depth': np.linspace(2, 12, 6), 'classifier__n_estimators': np.linspace(30,600,7), 'classifier__n_jobs': 6, }\n",
    "rf_pipe.get_params().keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.linspace(30,600,7).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}