{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
   }
  },
  "interpreter": {
   "hash": "f153955522cc68e74ca65e6cd89b55cb81ff123da8886c6f001578a93a739a7e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from random import randrange, random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, plot_confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.datasets import load_iris, load_wine\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from helper import *\n",
    "import math\n",
    "import logging\n",
    "from retrying import retry\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from itertools import islice\n",
    "from sklearn.ensemble import (GradientBoostingRegressor, GradientBoostingClassifier, AdaBoostClassifier,RandomForestClassifier)\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.inspection import partial_dependence, plot_partial_dependence\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pylab import rcParams\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "rcParams['figure.figsize'] = (12, 8)\n",
    "plt.style.use('ggplot')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d['list'][0].keys()\n",
    "replay_ids = []\n",
    "for i in range(200):\n",
    "    replay_ids.append(d['list'][i]['id'])\n",
    "replay_ids[0:5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def remove_extra_element(row):\n",
    "    if 'goals_against_while_last_defender' in row:\n",
    "        del row['goals_against_while_last_defender']\n",
    "    return row\n",
    "\n",
    "\n",
    "def create_frame_from_json(json_stats, rank_target):\n",
    "    df = pd.DataFrame.from_dict(json_stats)\n",
    "\n",
    "    df['core'] = df.stats.apply(lambda x:x['core'])\n",
    "    df['boost'] = df.stats.apply(lambda x:x['boost'])\n",
    "    df['movement'] = df.stats.apply(lambda x:x['movement'])\n",
    "    df['positioning'] = df.stats.apply(lambda x:x['positioning'])\n",
    "    df['demo'] = df.stats.apply(lambda x:x['demo'])\n",
    "    \n",
    "\n",
    "    rank_keys = list(df.iloc[0]['rank'].keys())\n",
    "    camera_keys = list(df.iloc[0]['camera'].keys())\n",
    "    core_stats_keys = list(df.iloc[0]['stats']['core'].keys())\n",
    "    boost_keys = list(df.iloc[0]['stats']['boost'].keys())\n",
    "    movement_keys = list(df.iloc[0]['stats']['movement'].keys())\n",
    "    positioning_keys = ['avg_distance_to_ball', 'avg_distance_to_ball_possession',\n",
    "        'avg_distance_to_ball_no_possession', 'avg_distance_to_mates',\n",
    "        'time_defensive_third', 'time_neutral_third', 'time_offensive_third',\n",
    "        'time_defensive_half', 'time_offensive_half', 'time_behind_ball',\n",
    "        'time_infront_ball', 'time_most_back', 'time_most_forward',\n",
    "        'time_closest_to_ball', 'time_farthest_from_ball',\n",
    "        'percent_defensive_third', 'percent_offensive_third',\n",
    "        'percent_neutral_third', 'percent_defensive_half',\n",
    "        'percent_offensive_half', 'percent_behind_ball', 'percent_infront_ball',\n",
    "        'percent_most_back', 'percent_most_forward', 'percent_closest_to_ball',\n",
    "        'percent_farthest_from_ball']\n",
    "    demo_keys = list(df.iloc[0]['stats']['demo'].keys())\n",
    "\n",
    "    df[rank_keys] = pd.json_normalize(df['rank'])\n",
    "    df[camera_keys] = pd.json_normalize(df['camera'])\n",
    "    df[core_stats_keys] = pd.json_normalize(df['core'])\n",
    "    df[boost_keys] = pd.json_normalize(df['boost'])\n",
    "    df[movement_keys] = pd.json_normalize(df['movement'])\n",
    "    df[demo_keys] = pd.json_normalize(df['demo'])\n",
    "\n",
    "    df['positioning'] = df.stats.apply(lambda x: remove_extra_element(x['positioning']))\n",
    "    df[positioning_keys] = pd.json_normalize(df['positioning'])\n",
    "    if rank_target == 'tier_div':\n",
    "        df['rank_target'] = df['tier'] * 4 + df['division']\n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df\n",
    "    if rank_target == 'tier':\n",
    "        df['rank_target'] = df['id'] \n",
    "        df = df.drop(['camera', 'stats', 'camera', 'rank', 'core', 'boost', 'movement', 'positioning', 'demo', 'start_time', 'end_time', 'name', 'id', 'car_id', 'tier', 'division'], axis=1)\n",
    "        return df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_all_ids():\n",
    "    season_lst = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','f1', 'f2', 'f3', 'f4']\n",
    "    replay_ids = []\n",
    "    for i in range(len(season_lst)):\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?player-name=LebaneseNinja&player-id=steam:76561198068157523&count=200&playlist=ranked-standard&season={season_lst[i]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        replay_ids.append(rank_ids)\n",
    "    return replay_ids\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stats_from_replays(replay_ids):\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "\n",
    "    orange_ranks = []\n",
    "    orange_stats = []\n",
    "    blue_ranks = []\n",
    "    blue_stats = []\n",
    "    pull_num = 0\n",
    "    for replay_id in replay_ids:\n",
    "        replay_stats = requests.get(f'https://ballchasing.com/api/replays/{replay_id}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        test_stats = replay_stats.json()\n",
    "        try:\n",
    "            ranks = [test_stats['orange']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            orange_ranks.append(ranks)\n",
    "            stats = [test_stats['orange']['players'][player] for player in range(3)]\n",
    "            orange_stats.append(stats[0])\n",
    "            orange_stats.append(stats[1])\n",
    "            orange_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            ranks = [test_stats['blue']['players'][player]['rank']['name'] for player in range(3)]\n",
    "            blue_ranks.append(ranks)\n",
    "            stats = [test_stats['blue']['players'][player] for player in range(3)]\n",
    "            blue_stats.append(stats[0])\n",
    "            blue_stats.append(stats[1])\n",
    "            blue_stats.append(stats[2])\n",
    "        except:\n",
    "            pass\n",
    "        pull_num += 1\n",
    "        logger.info(f'stats extracted for pull num {pull_num}')\n",
    "        \n",
    "    return blue_stats, orange_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def combine_clean_dfs(blue_df, orange_df, car_dummies):\n",
    "    combined_dfs = blue_df.append(orange_df)\n",
    "    combined_dfs['mvp'] = combined_dfs.mvp.apply(lambda x: 1 if x==True else 0)\n",
    "\n",
    "    if car_dummies == False:\n",
    "        combined_dfs = combined_dfs.drop('car_name', axis=1)\n",
    "        return combined_dfs\n",
    "    if car_dummies == True:\n",
    "        dummies = pd.get_dummies(combined_dfs.car_name, drop_first=True)\n",
    "        combined_concat_w_dummies = pd.concat([combined_dfs, dummies], axis=1)\n",
    "        combined_concat_w_dummies = combined_concat_w_dummies.drop('car_name', axis=1)\n",
    "        return combined_concat_w_dummies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_random_ids():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "    logger.info('starting pull')\n",
    "    minmax_rank_lst = [['bronze-1', 'bronze-3'], ['silver-1', 'silver-3'], ['gold-1', 'gold-3'], ['platinum-1', 'platinum-3'], ['diamond-1', 'diamond-3'], ['champion-1', 'champion-3'], ['champion-3', 'grand-champion']]\n",
    "    replay_ids = []\n",
    "    ids_pulled = []\n",
    "    for i in range(len(minmax_rank_lst)):\n",
    "        logger.info(f'pulling min_rank={minmax_rank_lst[i][0]}, max_rank = {minmax_rank_lst[i][1]}')\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard&min-rank={minmax_rank_lst[i][0]}&max-rank={minmax_rank_lst[i][1]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        count = d['count']\n",
    "        logger.info(f'count = {count}')\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "        if i == 6 or i == 5:\n",
    "            logger.info('i == 5 or 6, moving on')\n",
    "            replay_ids.append(rank_ids)\n",
    "            continue \n",
    "\n",
    "        logger.info('starting second pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        next_link = d['next']\n",
    "\n",
    "        logger.info('starting third pull')\n",
    "        r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        for i in range(len(d['list'])):\n",
    "            rank_ids.append(d['list'][i]['id'])\n",
    "        logger.info('rank pull complete.. appending results and moving to next rank') \n",
    "        replay_ids.append(rank_ids)\n",
    "\n",
    "    flat_list = [item for sublist in replay_ids for item in sublist]\n",
    "    return flat_list\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('full_nodummies.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "y = df.pop('rank_target')\n",
    "X = df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "kf = KFold(10)\n",
    "rf_pipe = Pipeline([('classifier', GradientBoostingRegressor())])\n",
    "rf_grid_params = {'classifier__max_features': ['sqrt', 'log2'], 'classifier__n_estimators': [900, 1000, 1100]}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'neg_mean_absolute_error')\n",
    "rf_grid.fit(X_train, y_train) \n",
    "print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))\n",
    "\n",
    "'''\n",
    "best estimator : [('classifier',\n",
    "                 GradientBoostingRegressor(max_features='sqrt',\n",
    "                                           n_estimators=900))])\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig, axs = plt.subplots(1,2)\n",
    "axs = axs.flatten()\n",
    "axs[0].hist(y_train)\n",
    "axs[0].set_title('y_train rank distribution')\n",
    "axs[0].set_ylabel('count')\n",
    "axs[0].set_xlabel('rank target')\n",
    "axs[1].hist(y_test)\n",
    "axs[1].set_title('y_test rank distribution')\n",
    "axs[1].set_ylabel('count')\n",
    "axs[1].set_xlabel('rank target');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "keras = tf.keras\n",
    "\n",
    "NN_model = keras.models.Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(keras.layers.Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(45, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split = 0.2)\n",
    "'''\n",
    "224/224 [==============================] - 0s 831us/step - loss: 7.2956 - mean_absolute_error: 7.2956 - val_loss: 7.2235 - val_mean_absolute_error: 7.2235\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_all():\n",
    "    logger = logging.getLogger(__name__)\n",
    "    log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    logging.basicConfig(filename = 'logging_info.log', level=logging.INFO, force=True, format=log_fmt)\n",
    "    logger.info('starting pull')\n",
    "    minmax_rank_lst = [['champion-1', 'champion-3'], ['champion-3', 'grand-champion']]\n",
    "    replay_ids = []\n",
    "    ids_pulled = []\n",
    "    for i in range(len(minmax_rank_lst)):\n",
    "        logger.info(f'pulling min_rank={minmax_rank_lst[i][0]}, max_rank = {minmax_rank_lst[i][1]}')\n",
    "        r = requests.get(f'https://ballchasing.com/api/replays?&count=200&playlist=ranked-standard&min-rank={minmax_rank_lst[i][0]}&max-rank={minmax_rank_lst[i][1]}', headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "        d = r.json()\n",
    "        rank_ids = []\n",
    "        count = d['count']\n",
    "        next_link = d['next']\n",
    "        logger.info(f'count = {count}')\n",
    "        for pull in range(math.floor(count/200)-2):\n",
    "            logger.info(f'starting pull number {pull+1}')\n",
    "            r = requests.get(next_link, headers={'Authorization': 'gMXy4BUhXt0OQhc37kJV5KP0GUyLzhJeZhogpa94'})\n",
    "            d = r.json()\n",
    "            try:\n",
    "                for i in range(len(d['list'])):\n",
    "                    rank_ids.append(d['list'][i]['id'])\n",
    "            except:\n",
    "                pass\n",
    "            next_link = d['next']\n",
    "        logger.info('rank pull complete.. appending results, saving series and moving to next rank') \n",
    "        replay_ids.append(rank_ids)\n",
    "        match_ids_tosave = pd.Series(replay_ids)\n",
    "        match_ids_tosave.to_csv('test_pull_all_ids.csv')\n",
    "    flat_list = [item for sublist in replay_ids for item in sublist]\n",
    "    return flat_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "up_to_d1 = pd.read_csv('up_to_diamond1.csv')\n",
    "d1uptochamp = pd.read_csv('diamond1_uptochamp1.csv')\n",
    "champtogc = pd.read_csv('champ_to_gc.csv')\n",
    "\n",
    "\n",
    "d1uptochampa = d1uptochamp.iloc[0]['0']\n",
    "da = d1uptochampa.split(',')\n",
    "da = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in da]\n",
    "\n",
    "\n",
    "champtogca = champtogc.iloc[0]['0']\n",
    "gca = champtogca.split(',')\n",
    "gca = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in gca]\n",
    "\n",
    "champtogcb = champtogc.iloc[1]['0']\n",
    "gcb = champtogcb.split(',')\n",
    "gcb = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in gcb]\n",
    "\n",
    "\n",
    "up_to_d1_a = up_to_d1.iloc[0]['0']\n",
    "a = up_to_d1_a.split(',')\n",
    "a = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in a]\n",
    "\n",
    "up_to_d1_b = up_to_d1.iloc[1]['0']\n",
    "b = up_to_d1_b.split(',')\n",
    "b = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in b]\n",
    "\n",
    "up_to_d1_c = up_to_d1.iloc[2]['0']\n",
    "c = up_to_d1_c.split(',')\n",
    "c = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in c]\n",
    "\n",
    "up_to_d1_d = up_to_d1.iloc[3]['0']\n",
    "d = up_to_d1_d.split(',')\n",
    "d = [i.replace('\"', '').replace('[', '').replace('\"\"', '').replace('\\'', '').replace(']', '') for i in d]\n",
    "\n",
    "res = []\n",
    "res.append(a)\n",
    "res.append(b)\n",
    "res.append(c)\n",
    "res.append(d)\n",
    "res.append(da)\n",
    "res.append(gca)\n",
    "res.append(gcb)\n",
    "\n",
    "flat_list = [item for sublist in res for item in sublist]\n",
    "res1 = []\n",
    "for i in flat_list:\n",
    "    if i not in res1:\n",
    "        res1.append(i)\n",
    "res1 = [i.replace(' ', '') for i in res1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# '27,095'\n",
    "# blue_stats, orange_stats = get_stats_from_replays(res1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# blue_df = create_frame_from_json(blue_stats, 'tier_div')\n",
    "# orange_df = create_frame_from_json(orange_stats, 'tier_div')\n",
    "# full_df = combine_clean_dfs(blue_df, orange_df, car_dummies=False)\n",
    "# full_df = full_df.dropna()\n",
    "# full_df.to_csv('final_full_data.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "\n",
    "train, holdout = train_test_split(X, y)\n",
    "holdout_y = holdout.pop('rank_target')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "\n",
    "keras = tf.keras\n",
    "\n",
    "NN_model = keras.models.Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(keras.layers.Dense(100, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(90, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(keras.layers.Dense(45, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(keras.layers.Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split = 0.2)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_train = np.mean(y_train)\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "mae_baseline = mean_absolute_error(y_test, baseline_predictions)\n",
    "print(\"Baseline MAE is {:.2f}\".format(mae_baseline))\n",
    "\n",
    "'''\n",
    "Baseline MAE is 7.85\n",
    "'''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    'objective':'reg:squarederror',\n",
    "}\n",
    "params['eval_metric'] = \"mae\"\n",
    "num_boost_round = 999\n",
    "\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# kf = KFold(10)\n",
    "# rf_pipe = Pipeline([('classifier', GradientBoostingRegressor())])\n",
    "# rf_grid = GridSearchCV(rf_pipe, rf_grid_params, cv=kf, scoring = 'neg_mean_absolute_error')\n",
    "# rf_grid.fit(X_train, y_train) \n",
    "# print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\tTest-mae:49.58604\n",
      "[1]\tTest-mae:34.73229\n",
      "[2]\tTest-mae:24.37727\n",
      "[3]\tTest-mae:17.26597\n",
      "[4]\tTest-mae:12.54000\n",
      "[5]\tTest-mae:9.54950\n",
      "[6]\tTest-mae:7.77488\n",
      "[7]\tTest-mae:6.76096\n",
      "[8]\tTest-mae:6.20538\n",
      "[9]\tTest-mae:5.87835\n",
      "[10]\tTest-mae:5.68468\n",
      "[11]\tTest-mae:5.57222\n",
      "[12]\tTest-mae:5.49715\n",
      "[13]\tTest-mae:5.45187\n",
      "[14]\tTest-mae:5.41608\n",
      "[15]\tTest-mae:5.38854\n",
      "[16]\tTest-mae:5.36477\n",
      "[17]\tTest-mae:5.34274\n",
      "[18]\tTest-mae:5.32739\n",
      "[19]\tTest-mae:5.31697\n",
      "[20]\tTest-mae:5.30176\n",
      "[21]\tTest-mae:5.29541\n",
      "[22]\tTest-mae:5.28581\n",
      "[23]\tTest-mae:5.27848\n",
      "[24]\tTest-mae:5.26997\n",
      "[25]\tTest-mae:5.26507\n",
      "[26]\tTest-mae:5.26025\n",
      "[27]\tTest-mae:5.25525\n",
      "[28]\tTest-mae:5.25391\n",
      "[29]\tTest-mae:5.24833\n",
      "[30]\tTest-mae:5.24510\n",
      "[31]\tTest-mae:5.24162\n",
      "[32]\tTest-mae:5.23583\n",
      "[33]\tTest-mae:5.23229\n",
      "[34]\tTest-mae:5.22699\n",
      "[35]\tTest-mae:5.22514\n",
      "[36]\tTest-mae:5.22091\n",
      "[37]\tTest-mae:5.21578\n",
      "[38]\tTest-mae:5.21571\n",
      "[39]\tTest-mae:5.21288\n",
      "[40]\tTest-mae:5.21253\n",
      "[41]\tTest-mae:5.21223\n",
      "[42]\tTest-mae:5.21190\n",
      "[43]\tTest-mae:5.20949\n",
      "[44]\tTest-mae:5.20715\n",
      "[45]\tTest-mae:5.20564\n",
      "[46]\tTest-mae:5.20591\n",
      "[47]\tTest-mae:5.20383\n",
      "[48]\tTest-mae:5.20152\n",
      "[49]\tTest-mae:5.19574\n",
      "[50]\tTest-mae:5.19517\n",
      "[51]\tTest-mae:5.19257\n",
      "[52]\tTest-mae:5.19150\n",
      "[53]\tTest-mae:5.19053\n",
      "[54]\tTest-mae:5.18887\n",
      "[55]\tTest-mae:5.18551\n",
      "[56]\tTest-mae:5.18308\n",
      "[57]\tTest-mae:5.18162\n",
      "[58]\tTest-mae:5.18221\n",
      "[59]\tTest-mae:5.18076\n",
      "[60]\tTest-mae:5.17749\n",
      "[61]\tTest-mae:5.17831\n",
      "[62]\tTest-mae:5.17620\n",
      "[63]\tTest-mae:5.17460\n",
      "[64]\tTest-mae:5.17420\n",
      "[65]\tTest-mae:5.17285\n",
      "[66]\tTest-mae:5.17182\n",
      "[67]\tTest-mae:5.17071\n",
      "[68]\tTest-mae:5.16952\n",
      "[69]\tTest-mae:5.16637\n",
      "[70]\tTest-mae:5.16438\n",
      "[71]\tTest-mae:5.16283\n",
      "[72]\tTest-mae:5.16222\n",
      "[73]\tTest-mae:5.16065\n",
      "[74]\tTest-mae:5.15810\n",
      "[75]\tTest-mae:5.15774\n",
      "[76]\tTest-mae:5.15819\n",
      "[77]\tTest-mae:5.15738\n",
      "[78]\tTest-mae:5.15626\n",
      "[79]\tTest-mae:5.15608\n",
      "[80]\tTest-mae:5.15286\n",
      "[81]\tTest-mae:5.15103\n",
      "[82]\tTest-mae:5.14975\n",
      "[83]\tTest-mae:5.14905\n",
      "[84]\tTest-mae:5.14993\n",
      "[85]\tTest-mae:5.15032\n",
      "[86]\tTest-mae:5.15275\n",
      "[87]\tTest-mae:5.15146\n",
      "[88]\tTest-mae:5.15116\n",
      "[89]\tTest-mae:5.15206\n",
      "[90]\tTest-mae:5.15137\n",
      "[91]\tTest-mae:5.15039\n",
      "[92]\tTest-mae:5.14972\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'mae'},\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "cv_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
       "0        49.513971       0.006593      49.509098      0.042227\n",
       "1        34.676733       0.003962      34.668917      0.051957\n",
       "2        24.315287       0.003745      24.319977      0.053852\n",
       "3        17.188720       0.003881      17.225472      0.054131\n",
       "4        12.427199       0.007642      12.502097      0.055045\n",
       "..             ...            ...            ...           ...\n",
       "76        4.053479       0.011707       5.173548      0.036657\n",
       "77        4.043412       0.014109       5.172695      0.035964\n",
       "78        4.031641       0.015042       5.173172      0.034504\n",
       "79        4.020114       0.013908       5.172474      0.034381\n",
       "80        4.008826       0.013653       5.171941      0.034435\n",
       "\n",
       "[81 rows x 4 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.513971</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>49.509098</td>\n",
       "      <td>0.042227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.676733</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>34.668917</td>\n",
       "      <td>0.051957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.315287</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>24.319977</td>\n",
       "      <td>0.053852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.188720</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>17.225472</td>\n",
       "      <td>0.054131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.427199</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>12.502097</td>\n",
       "      <td>0.055045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4.053479</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>5.173548</td>\n",
       "      <td>0.036657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>4.043412</td>\n",
       "      <td>0.014109</td>\n",
       "      <td>5.172695</td>\n",
       "      <td>0.035964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>4.031641</td>\n",
       "      <td>0.015042</td>\n",
       "      <td>5.173172</td>\n",
       "      <td>0.034504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>4.020114</td>\n",
       "      <td>0.013908</td>\n",
       "      <td>5.172474</td>\n",
       "      <td>0.034381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4.008826</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>5.171941</td>\n",
       "      <td>0.034435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows Ã— 4 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "cv_results['test-mae-mean'].min()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5.1719414"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(2,4)\n",
    "    for min_child_weight in range(5,8)\n",
    "]\n",
    "\n",
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))    \n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight    \n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )  \n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CV with max_depth=2, min_child_weight=5\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "params['max_depth'] = 5\n",
    "params['min_child_weight'] = 5\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'mae'},\n",
    "        early_stopping_rounds=10\n",
    "    )    # Update best score\n",
    "    mean_mae = cv_results['test-mae-mean'].min()\n",
    "    boost_rounds = cv_results['test-mae-mean'].argmin()\n",
    "    print(\"\\tMAE {} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "        print(\"Best params: {}, {}, MAE: {}\".format(best_params[0], best_params[1], min_mae))CV with subsample=1.0, colsample=1.0\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "full_df = full_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train, holdout = train_test_split(full_df, test_size=0.2)\n",
    "\n",
    "label = np.array(train.pop('rank_target'))\n",
    "X = np.array(train)\n",
    "dtrain = xgb.DMatrix(X, label=label)\n",
    "\n",
    "holdout_label = np.array(holdout.pop('rank_target'))\n",
    "holdout_X = np.array(holdout)\n",
    "holdout_dtest = xgb.DMatrix(holdout_X, label=holdout_label)\n",
    "\n",
    "\n",
    "param = {'eval_metric': 'mae'}\n",
    "param['nthread'] = 6\n",
    "evallist = [(dtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param, dtrain, 20,  evallist)\n",
    "ypred = bst.predict(holdout_dtest)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_df = pd.read_csv('final_full_data.csv')\n",
    "full_df = full_df.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "y = full_df.pop('rank_target')\n",
    "X = full_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, shuffle=True)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "kf = KFold(10)\n",
    "params = {'classifier__objective': ['reg:squarederror'], 'classifier__max_depth': np.linspace(2, 12, 6).astype(int), 'classifier__n_estimators': np.linspace(30,600,7).astype(int), 'classifier__n_jobs': [6], }\n",
    "rf_pipe = Pipeline([('classifier', xgb.XGBRegressor())])\n",
    "rf_grid = GridSearchCV(rf_pipe, param_grid = params, cv=kf)\n",
    "rf_grid.fit(X_train, y_train) \n",
    "print(\"Gradient Boosting Mean Absolute Error: {}\".format(rf_grid.score(X_test, y_test)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rf_pipe = Pipeline([('classifier', xgb.XGBRegressor())])\n",
    "params = {'classifier__objective': 'reg:squarederror', 'eval_metric': 'mae', 'classifier__max_depth': np.linspace(2, 12, 6), 'classifier__n_estimators': np.linspace(30,600,7), 'classifier__n_jobs': 6, }\n",
    "rf_pipe.get_params().keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.linspace(30,600,7).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}